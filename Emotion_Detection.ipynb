{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9KuIpa_p3gj"
   },
   "source": [
    "Ipython notebook for emotion detection from text using LSTM (Long short term memory.\n",
    "The first step is the data preprocessing of the corwdflower dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8LL4vQYYsX4n"
   },
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,LSTM,Input,Bidirectional\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNjDjl_Aq4L5"
   },
   "source": [
    "Mounting the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2zqjb2hp0Yk",
    "outputId": "0b46629f-e64d-49bc-db87-bb20b84dbbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbYqXZFdrf5r"
   },
   "source": [
    "Importing the datasets from the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZ-dmbLkrNpL",
    "outputId": "019753e3-2d1d-4ba4-8eab-1c05776e0bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/content/drive/My Drive/text_emotion.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PU9yiknruS4"
   },
   "source": [
    "Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaudXnLVrs54",
    "outputId": "a5ab0674-ce05-4a7e-dc53-e22775e8223d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tweet_id  ...                                            content\n",
      "0  1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n",
      "1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2  1956967696  ...                Funeral ceremony...gloomy friday...\n",
      "3  1956967789  ...               wants to hang out with friends SOON!\n",
      "4  1956968416  ...  @dannycastillo We want to trade with someone w...\n",
      "\n",
      "[5 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WIbyeEMsCyh"
   },
   "source": [
    "The tweet_id and author name are of no use to us. So drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_S-EIJtXr6SV",
    "outputId": "731e2c8b-4eb5-4b67-c856-0616c50dfd24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentiment                                            content\n",
      "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
      "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
      "2     sadness                Funeral ceremony...gloomy friday...\n",
      "3  enthusiasm               wants to hang out with friends SOON!\n",
      "4     neutral  @dannycastillo We want to trade with someone w...\n"
     ]
    }
   ],
   "source": [
    "df=df.drop(['tweet_id','author'], axis = 1) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGHoXhPXsuK_"
   },
   "source": [
    "Now, we have all the required columns. Now, using NLP for text preprocessing"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Emotion Detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
